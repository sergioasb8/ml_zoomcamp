{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Info\n",
    "\n",
    "Notebook with all the code needed to solve the homework for the third week of the machine learning zoomcamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split # SplitData\n",
    "from sklearn.metrics import mutual_info_score #MI\n",
    "from sklearn.preprocessing import OneHotEncoder # OneHotEncoding\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data\n",
    "\n",
    " \n",
    "For this homework, we'll use the Car price dataset. Download it from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-02-car-price/data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll keep working with the MSRP variable, and we'll transform it to a classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n",
    "For the rest of the homework, you'll need to use only these columns:\n",
    "\n",
    "* Make\n",
    "* Model\n",
    "* Year\n",
    "* Engine HP\n",
    "* Engine Cylinders\n",
    "* Transmission Type\n",
    "* Vehicle Style\n",
    "* highway MPG\n",
    "* city mpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Select only the features from above and transform their names using next line:\n",
    "\n",
    "__data.columns = data.columns.str.replace(' ', '_').str.lower()__\n",
    "\n",
    "Fill in the missing values of the selected features with 0.\n",
    "\n",
    "Rename MSRP variable to price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = data.columns.str.replace(' ','_').str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data[['make','model','year','engine_hp','engine_cylinders','transmission_type','vehicle_style','highway_mpg','city_mpg','msrp']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'msrp':'price'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column transmission_type?\n",
    "\n",
    "* AUTOMATIC\n",
    "* MANUAL\n",
    "* AUTOMATED_MANUAL\n",
    "* DIRECT_DRIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AUTOMATIC           8266\n",
       "MANUAL              2935\n",
       "AUTOMATED_MANUAL     626\n",
       "DIRECT_DRIVE          68\n",
       "UNKNOWN               19\n",
       "Name: transmission_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['transmission_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent observation is __Automatic__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Create the correlation matrix for the numerical features of your dataset. In a correlation matrix, you compute the correlation coefficient between every pair of features in the dataset.\n",
    "\n",
    "What are the two features that have the biggest correlation in this dataset?\n",
    "\n",
    "* engine_hp and year\n",
    "* engine_hp and engine_cylinders\n",
    "* highway_mpg and engine_cylinders\n",
    "* highway_mpg and city_mpg\n",
    "\n",
    "Make price binary\n",
    "\n",
    "* Now we need to turn the price variable from numeric into a binary format.\n",
    "* Let's create a variable above_average which is 1 if the price is above its mean value and 0 otherwise.\n",
    "\n",
    "Split the data\n",
    "\n",
    "* Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "* Use Scikit-Learn for that (the train_test_split function) and set the seed to 42.\n",
    "* Make sure that the target value (price) is not in your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['year','engine_hp','engine_cylinders','highway_mpg','city_mpg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>engine_hp</th>\n",
       "      <th>engine_cylinders</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>city_mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.338714</td>\n",
       "      <td>-0.040708</td>\n",
       "      <td>0.258240</td>\n",
       "      <td>0.198171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine_hp</th>\n",
       "      <td>0.338714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.774851</td>\n",
       "      <td>-0.415707</td>\n",
       "      <td>-0.424918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>engine_cylinders</th>\n",
       "      <td>-0.040708</td>\n",
       "      <td>0.774851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.614541</td>\n",
       "      <td>-0.587306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>highway_mpg</th>\n",
       "      <td>0.258240</td>\n",
       "      <td>-0.415707</td>\n",
       "      <td>-0.614541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city_mpg</th>\n",
       "      <td>0.198171</td>\n",
       "      <td>-0.424918</td>\n",
       "      <td>-0.587306</td>\n",
       "      <td>0.886829</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      year  engine_hp  engine_cylinders  highway_mpg  city_mpg\n",
       "year              1.000000   0.338714         -0.040708     0.258240  0.198171\n",
       "engine_hp         0.338714   1.000000          0.774851    -0.415707 -0.424918\n",
       "engine_cylinders -0.040708   0.774851          1.000000    -0.614541 -0.587306\n",
       "highway_mpg       0.258240  -0.415707         -0.614541     1.000000  0.886829\n",
       "city_mpg          0.198171  -0.424918         -0.587306     0.886829  1.000000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical_columns].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The biggest correlation matrix is __highway_mpg and city_mpg__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make price binary\n",
    "df['above_average'] = (df['price'] > np.mean(df['price'])).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "seed = 42\n",
    "\n",
    "df_train_full, df_test = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "df_train, df_val = train_test_split(df_train_full, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2383, 7148, 2383)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.shape[0], df_train.shape[0], df_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['above_average']\n",
    "y_val = df_val['above_average']\n",
    "y_test = df_test['above_average']\n",
    "\n",
    "del df_train['above_average']\n",
    "del df_val['above_average']\n",
    "del df_test['above_average']\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>make</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>engine_hp</th>\n",
       "      <th>engine_cylinders</th>\n",
       "      <th>transmission_type</th>\n",
       "      <th>vehicle_style</th>\n",
       "      <th>highway_mpg</th>\n",
       "      <th>city_mpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Beetle</td>\n",
       "      <td>2015</td>\n",
       "      <td>210.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>2dr Hatchback</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9951</th>\n",
       "      <td>Audi</td>\n",
       "      <td>SQ5</td>\n",
       "      <td>2015</td>\n",
       "      <td>354.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>AUTOMATIC</td>\n",
       "      <td>4dr SUV</td>\n",
       "      <td>24</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            make   model  year  engine_hp  engine_cylinders transmission_type  \\\n",
       "1918  Volkswagen  Beetle  2015      210.0               4.0            MANUAL   \n",
       "9951        Audi     SQ5  2015      354.0               6.0         AUTOMATIC   \n",
       "\n",
       "      vehicle_style  highway_mpg  city_mpg  \n",
       "1918  2dr Hatchback           31        23  \n",
       "9951        4dr SUV           24        17  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "* Calculate the mutual information score between above_average and other categorical variables in our dataset. Use the training set only.\n",
    "* Round the scores to 2 decimals using round(score, 2).\n",
    "\n",
    "Which of these variables has the lowest mutual information score?\n",
    "\n",
    "* make\n",
    "* model\n",
    "* transmission_type\n",
    "* vehicle_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['make','model','transmission_type','vehicle_style']\n",
    "\n",
    "def calculate_mi(series):\n",
    "    return mutual_info_score(series, y_train)\n",
    "\n",
    "df_mi = df_train[categorical_variables].apply(calculate_mi).round(2)\n",
    "df_mi = df_mi.sort_values(ascending=False).to_frame(name='MI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vehicle_style</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>transmission_type</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     MI\n",
       "model              0.46\n",
       "make               0.24\n",
       "vehicle_style      0.08\n",
       "transmission_type  0.02"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lowest mutual info score is __transmission_type__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Question 4\n",
    "\n",
    "* Now let's train a logistic regression.\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    - model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "* 0.60\n",
    "* 0.72\n",
    "* 0.84\n",
    "* 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[categorical_variables + numerical_columns].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val[categorical_variables + numerical_columns].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, max_iter=1000, random_state=42, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, max_iter=1000, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.93\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "y_pred = model.predict(X_val)\n",
    "\n",
    "# accuracy\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "print(f\"accuracy = {accuracy.round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "* Let's find the least useful feature using the feature elimination technique.\n",
    "* Train a model with all these features (using the same parameters as in Q4).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature.\n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "* year\n",
    "* engine_hp\n",
    "* transmission_type\n",
    "* city_mpg\n",
    "\n",
    "Note: the difference doesn't have to be positive\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.94713 without year, difference with previous = 0.01259\n",
      "accuracy = 0.93034 without engine_hp, difference with previous = 0.0042\n",
      "accuracy = 0.94587 without transmission_type, difference with previous = 0.01133\n",
      "accuracy = 0.94629 without city_mpg, difference with previous = 0.01175\n"
     ]
    }
   ],
   "source": [
    "for feature_col in ['year','engine_hp','transmission_type','city_mpg']:\n",
    "\n",
    "    # create a copy of the data\n",
    "    df_train_new = df_train.copy()\n",
    "    df_val_new = df_val.copy()\n",
    "\n",
    "    # encoding\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "\n",
    "    train_dict = df_train_new[categorical_variables + numerical_columns].drop(columns=feature_col, axis=1).to_dict(orient='records')\n",
    "    X_train = dv.fit_transform(train_dict)\n",
    "    val_dict = df_val_new[categorical_variables + numerical_columns].drop(columns=feature_col, axis=1).to_dict(orient='records')\n",
    "    X_val = dv.transform(val_dict)\n",
    "\n",
    "    # initialize and train the Logistic Regression model\n",
    "    model = LogisticRegression(solver='liblinear', C=10, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # accuracy\n",
    "    new_accuracy = accuracy_score(y_val, y_pred)\n",
    "    print(f\"accuracy = {new_accuracy.round(5)} without {feature_col}, difference with previous = {abs((accuracy-new_accuracy).round(5))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The smallest difference is 0.0042 and it is get without enigne_hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "* For this question, we'll see how to use a linear regression model from Scikit-Learn.\n",
    "* We'll need to use the original column price. Apply the logarithmic transformation to this column.\n",
    "* Fit the Ridge regression model on the training data with a solver 'sag'. Set the seed to 42.\n",
    "* This model also has a parameter alpha. Let's try the following values: [0, 0.01, 0.1, 1, 10].\n",
    "* Round your RMSE scores to 3 decimal digits.\n",
    "\n",
    "Which of these alphas leads to the best RMSE on the validation set?\n",
    "\n",
    "* 0\n",
    "* 0.01\n",
    "* 0.1\n",
    "* 1\n",
    "* 10\n",
    "\n",
    "Note: If there are multiple options, select the smallest alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "df_6 = df[['make','model','year','engine_hp','engine_cylinders','transmission_type','vehicle_style','highway_mpg','city_mpg','price']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df_6, test_size=0.2, random_state=42)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log1p(df_train['price'])\n",
    "y_val = np.log1p(df_val['price'])\n",
    "y_test = np.log1p(df_test['price'])\n",
    "\n",
    "del df_train['price']\n",
    "del df_val['price']\n",
    "del df_test['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dicts = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only this time because is not a big warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha = 0, mean squared error  0.487\n",
      "alpha = 0.01, mean squared error  0.487\n",
      "alpha = 0.1, mean squared error  0.487\n",
      "alpha = 1, mean squared error  0.487\n",
      "alpha = 10, mean squared error  0.487\n"
     ]
    }
   ],
   "source": [
    "train_dicts = df_train.to_dict(orient='records')\n",
    "val_dicts = df_val.to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "X_val = dv.transform(val_dicts)\n",
    "alphas = [0, 0.01, 0.1, 1, 10]\n",
    "\n",
    "for a in alphas:\n",
    "    model = Ridge(solver='sag', alpha=a, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    print(f\"alpha = {a}, mean squared error  {round(mean_squared_error(y_val, y_pred, squared=False), 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of them return the same RMSE, so the lowest alpha will be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
