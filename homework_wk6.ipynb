{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Info\n",
    "\n",
    "Notebook with all the code needed to solve the homework for the week six of the machine learning zoomcamp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor, export_text\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "import pickle\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data\n",
    "\n",
    "In this homework, we will use the California Housing Prices from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/housing.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "* We are going to use all columns of the dataset.\n",
    "* First, keep only the records where ocean_proximity is either '<1H OCEAN' or 'INLAND'\n",
    "* Fill missing values with zeros.\n",
    "* Apply the log tranform to median_house_value.\n",
    "* Do train/validation/test split with 60%/20%/20% distribution.\n",
    "* Use the train_test_split function and set the random_state parameter to 1.\n",
    "* Use DictVectorizer(sparse=True) to turn the dataframes into matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(data):\n",
    "\n",
    "    df = data[(data[\"ocean_proximity\"] == \"<1H OCEAN\") | (data[\"ocean_proximity\"] == \"INLAND\")].copy()\n",
    "\n",
    "    df.fillna(0, inplace=True)\n",
    "\n",
    "    # adding some data cleaning for the xboost \n",
    "    df['ocean_proximity'] = df['ocean_proximity'].str.replace('<','under_')\n",
    "\n",
    "    df[\"median_house_value\"] = np.log1p(df[\"median_house_value\"])\n",
    "    df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "    df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "    df_train = df_train.reset_index(drop=True).copy()\n",
    "    df_val = df_val.reset_index(drop=True).copy()\n",
    "    df_test = df_test.reset_index(drop=True).copy()\n",
    "\n",
    "    y_train = df_train[\"median_house_value\"].values\n",
    "    y_val = df_val[\"median_house_value\"].values\n",
    "    y_test = df_test[\"median_house_value\"].values\n",
    "\n",
    "\n",
    "    df_train.drop(labels=['median_house_value'], axis=1, inplace=True)\n",
    "    df_val.drop(labels=['median_house_value'], axis=1, inplace=True)\n",
    "    df_test.drop(labels=['median_house_value'], axis=1, inplace=True)\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "\n",
    "    X_train = dv.fit_transform(df_train.to_dict(orient='records'))\n",
    "    X_test = dv.fit_transform(df_test.to_dict(orient='records'))\n",
    "    X_val = dv.fit_transform(df_val.to_dict(orient='records'))\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, dv\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, dv = data_preparation(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Let's train a decision tree regressor to predict the median_house_value variable.\n",
    "\n",
    "Train a model with max_depth=1.\n",
    "Which feature is used for splitting the data?\n",
    "\n",
    "* ocean_proximity\n",
    "* total_rooms\n",
    "* latitude\n",
    "* population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature used for splitting the data is ocean_proximity=under_1H OCEAN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_names = [i for i in dv.get_feature_names_out()]\n",
    "\n",
    "regressor = DecisionTreeRegressor(max_depth=1)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "feature_index = regressor.tree_.feature[0]\n",
    "feature_name = feature_names[feature_index]\n",
    "\n",
    "print(f\"The feature used for splitting the data is {feature_name}\")\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Train a random forest model with these parameters:\n",
    "\n",
    "* n_estimators=10\n",
    "* random_state=1\n",
    "* n_jobs=-1 (optional - to make training faster)\n",
    "\n",
    "What's the RMSE of this model on validation?\n",
    "\n",
    "* 0.045\n",
    "* 0.245\n",
    "* 0.545\n",
    "* 0.845"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.245\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=10, random_state=1, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "\n",
    "print(f\"RMSE = {round(rmse,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Now let's experiment with the n_estimators parameter\n",
    "\n",
    "* Try different values of this parameter from 10 to 200 with step 10.\n",
    "* Set random_state to 1.\n",
    "* Evaluate the model on the validation dataset.\n",
    "\n",
    "After which value of n_estimators does RMSE stop improving?\n",
    "\n",
    "* 10\n",
    "* 25\n",
    "* 50\n",
    "* 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_range = range(10, 201, 10)\n",
    "\n",
    "estimators = []\n",
    "rmse_list = []\n",
    "# best_rmse = float('inf')\n",
    "# best_n_estimators = 0\n",
    "\n",
    "for estimator_value in n_estimators_range:\n",
    "    model_rf = RandomForestRegressor(\n",
    "        n_estimators=estimator_value, \n",
    "        random_state=1)\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    y_pred = model_rf.predict(X_val)\n",
    "\n",
    "    rmse = round(np.sqrt(mean_squared_error(y_val, y_pred)),3)\n",
    "    estimators.append(estimator_value)\n",
    "    rmse_list.append(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>0.235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>120</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>130</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>140</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>160</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>170</td>\n",
       "      <td>0.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>180</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>190</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>0.234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    estimator   rmse\n",
       "0          10  0.245\n",
       "1          20  0.239\n",
       "2          30  0.237\n",
       "3          40  0.235\n",
       "4          50  0.235\n",
       "5          60  0.234\n",
       "6          70  0.234\n",
       "7          80  0.235\n",
       "8          90  0.235\n",
       "9         100  0.234\n",
       "10        110  0.234\n",
       "11        120  0.234\n",
       "12        130  0.234\n",
       "13        140  0.234\n",
       "14        150  0.234\n",
       "15        160  0.233\n",
       "16        170  0.233\n",
       "17        180  0.234\n",
       "18        190  0.234\n",
       "19        200  0.234"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'estimator':estimators,'rmse':rmse_list}).sort_values(by=['estimator'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "Let's select the best max_depth:\n",
    "\n",
    "* Try different values of max_depth: [10, 15, 20, 25]\n",
    "* For each of these values, try different values of n_estimators from 10 till 200 (with step 10)\n",
    "* Fix the random seed: random_state=1\n",
    "\n",
    "What's the best max_depth:\n",
    "\n",
    "* 10\n",
    "* 15\n",
    "* 20\n",
    "* 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "\n",
    "for max_depth in [10, 15, 20, 25]:\n",
    "    for n_estimators in range(10, 201, 10):\n",
    "        rf = RandomForestRegressor(\n",
    "            n_estimators=n_estimators, \n",
    "            max_depth=max_depth,\n",
    "            random_state=1\n",
    "            )\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = rf.predict(X_val)\n",
    "        rmse = round(np.sqrt(mean_squared_error(y_val, y_pred)), 3)\n",
    "        scores.append((n_estimators, max_depth, rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "max_depth\n",
       "10    0.24525\n",
       "15    0.23645\n",
       "20    0.23510\n",
       "25    0.23485\n",
       "Name: rmse, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_columns = [\"n_estimators\",\"max_depth\", \"rmse\"]\n",
    "df_scores = pd.DataFrame(scores,columns=data_columns)\n",
    "df_scores.groupby(['max_depth'])['rmse'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "We can extract feature importance information from tree-based models.\n",
    "\n",
    "At each step of the decision tree learning algorith, it finds the best split. When doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. This gain is quite useful in understanding what are the imporatant features for tree-based models.\n",
    "\n",
    "In Scikit-Learn, tree-based models contain this information in the feature_importances_ field.\n",
    "\n",
    "For this homework question, we'll find the most important feature:\n",
    "\n",
    "* Train the model with these parametes:\n",
    "    * n_estimators=10,\n",
    "    * max_depth=20,\n",
    "    * random_state=1,\n",
    "    * n_jobs=-1 (optional)\n",
    "* Get the feature importance information from this model\n",
    "\n",
    "What's the most important feature (among these 4)?\n",
    "\n",
    "* total_rooms\n",
    "* median_income\n",
    "* total_bedrooms\n",
    "* longitude\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestRegressor(max_depth=20, n_estimators=10, n_jobs=-1, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor(max_depth=20, n_estimators=10, n_jobs=-1, random_state=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestRegressor(max_depth=20, n_estimators=10, n_jobs=-1, random_state=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=10,\n",
    "    max_depth=20,\n",
    "    random_state=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>median_income</td>\n",
       "      <td>0.336561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ocean_proximity=under_1H OCEAN</td>\n",
       "      <td>0.231230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ocean_proximity=INLAND</td>\n",
       "      <td>0.133051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>latitude</td>\n",
       "      <td>0.100664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>longitude</td>\n",
       "      <td>0.086560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>housing_median_age</td>\n",
       "      <td>0.032059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>population</td>\n",
       "      <td>0.027506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>total_rooms</td>\n",
       "      <td>0.021402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total_bedrooms</td>\n",
       "      <td>0.015813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>households</td>\n",
       "      <td>0.015155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          feature  importance\n",
       "4                   median_income    0.336561\n",
       "6  ocean_proximity=under_1H OCEAN    0.231230\n",
       "5          ocean_proximity=INLAND    0.133051\n",
       "2                        latitude    0.100664\n",
       "3                       longitude    0.086560\n",
       "1              housing_median_age    0.032059\n",
       "7                      population    0.027506\n",
       "9                     total_rooms    0.021402\n",
       "8                  total_bedrooms    0.015813\n",
       "0                      households    0.015155"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance_df = pd.DataFrame({'feature':dv.feature_names_,'importance':rf.feature_importances_})\n",
    "importance_df.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "Now let's train an XGBoost model! For this question, we'll tune the eta parameter:\n",
    "\n",
    "* Install XGBoost\n",
    "* Create DMatrix for train and validation\n",
    "* Create a watchlist\n",
    "* Train a model with these parameters for 100 rounds:\n",
    "\n",
    "```Python\n",
    "    xgb_params = {\n",
    "        'eta': 0.3, \n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 1,\n",
    "        \n",
    "        'objective': 'reg:squarederror',\n",
    "        'nthread': 8,\n",
    "        \n",
    "        'seed': 1,\n",
    "        'verbosity': 1,\n",
    "    }\n",
    "```\n",
    "\n",
    "Now change eta from 0.3 to 0.1.\n",
    "\n",
    "Which eta leads to the best RMSE score on the validation dataset?\n",
    "\n",
    "* 0.3\n",
    "* 0.1\n",
    "* Both give equal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = dv.feature_names_\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(dtrain,'train'),(dval, 'validation')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:8.07362\tvalidation-rmse:8.07348\n",
      "[10]\ttrain-rmse:0.33195\tvalidation-rmse:0.34802\n",
      "[20]\ttrain-rmse:0.20036\tvalidation-rmse:0.24508\n",
      "[30]\ttrain-rmse:0.18204\tvalidation-rmse:0.23833\n",
      "[40]\ttrain-rmse:0.16422\tvalidation-rmse:0.23379\n",
      "[50]\ttrain-rmse:0.15210\tvalidation-rmse:0.23262\n",
      "[60]\ttrain-rmse:0.14218\tvalidation-rmse:0.23160\n",
      "[70]\ttrain-rmse:0.13471\tvalidation-rmse:0.23108\n",
      "[80]\ttrain-rmse:0.12835\tvalidation-rmse:0.23045\n",
      "[90]\ttrain-rmse:0.12174\tvalidation-rmse:0.22957\n",
      "[99]\ttrain-rmse:0.11656\tvalidation-rmse:0.22897\n"
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.3, \n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 1,\n",
    "    \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': 8,\n",
    "    \n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100, verbose_eval=10, evals=watchlist)\n",
    "y_pred = model.predict(dval)\n",
    "initial_rmse = np.sqrt(np.mean((y_val - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:10.37456\tvalidation-rmse:10.37545\n",
      "[10]\ttrain-rmse:3.63299\tvalidation-rmse:3.62939\n",
      "[20]\ttrain-rmse:1.29412\tvalidation-rmse:1.29329\n",
      "[30]\ttrain-rmse:0.50217\tvalidation-rmse:0.51149\n",
      "[40]\ttrain-rmse:0.26743\tvalidation-rmse:0.29345\n",
      "[50]\ttrain-rmse:0.21112\tvalidation-rmse:0.24907\n",
      "[60]\ttrain-rmse:0.19724\tvalidation-rmse:0.24107\n",
      "[70]\ttrain-rmse:0.18911\tvalidation-rmse:0.23824\n",
      "[80]\ttrain-rmse:0.18145\tvalidation-rmse:0.23594\n",
      "[90]\ttrain-rmse:0.17418\tvalidation-rmse:0.23307\n",
      "[99]\ttrain-rmse:0.17000\tvalidation-rmse:0.23234\n"
     ]
    }
   ],
   "source": [
    "xgb_params['eta'] = 0.1\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=100, verbose_eval=10, evals=watchlist)\n",
    "y_pred = model.predict(dval)\n",
    "updated_rmse = np.sqrt(np.mean((y_val - y_pred) ** 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
